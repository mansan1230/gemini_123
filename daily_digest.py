import os
import requests
import json
import time
import yfinance as yf # å¼•å…¥ Yahoo Finance
import google.generativeai as genai
from datetime import datetime

# ================= 1. è¨­å®šå€ =================
NEWS_API_KEY = os.getenv("NEWS_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Debug
print(f"Checking Keys...")
print(f"- NEWS: {'âœ…' if NEWS_API_KEY else 'âŒ'}")
print(f"- GEMINI: {'âœ…' if GEMINI_API_KEY else 'âŒ'}")

# æ¨¡å‹è¨­å®š (Gemini 1.5 Flash)
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY.strip())
    model = genai.GenerativeModel(
        'gemini-2.0-flash',
        generation_config={"response_mime_type": "application/json"}
    )

# æ–°èé—œéµå­—
CATEGORIES = {
    "ğŸ”¥ å¸‚å ´é ­æ¢": "stock market OR federal reserve OR economy",
    "ğŸ¤– äººå·¥æ™ºæ…§": "Artificial Intelligence OR Nvidia OR OpenAI",
    "ğŸ’° åŠ å¯†è²¨å¹£": "Bitcoin OR Ethereum OR Crypto"
}

# ================= 2. æŠ“å–å‡½æ•¸ (yfinance ç‰ˆ) =================

def get_market_and_macro():
    """
    ä¸€æ¬¡éæŠ“å–ã€Œå¸‚å ´æŒ‡æ•¸ã€åŒã€Œå®è§€æŒ‡æ¨™ã€
    ä½¿ç”¨ yfinanceï¼Œå®Œå…¨å…è²»ï¼Œä¸ç”¨ Key
    """
    print("ğŸ“Š æ­£åœ¨é€é Yahoo Finance æŠ“å–æ•¸æ“š...")
    
    # å®šç¾©ä»£ç¢¼
    tickers = {
        # --- å¸‚å ´æŒ‡æ•¸ ---
        "ğŸ‡ºğŸ‡¸ S&P 500": "^GSPC",
        "ğŸ‡ºğŸ‡¸ Nasdaq": "^IXIC",
        "ğŸ‡­ğŸ‡° æ’ç”ŸæŒ‡æ•¸": "^HSI",
        "ğŸª™ Bitcoin": "BTC-USD",
        
        # --- å®è§€æŒ‡æ¨™ (å–ä»£æ—¥æ›†) ---
        "ğŸ˜° ææ…ŒæŒ‡æ•¸ (VIX)": "^VIX",
        "ğŸ‡ºğŸ‡¸ 10å¹´ç¾å‚µ": "^TNX",
        "ğŸ’µ ç¾å…ƒæŒ‡æ•¸": "DX-Y.NYB",
        "ğŸ›¢ï¸ åŸæ²¹ (WTI)": "CL=F"
    }
    
    data_list = []
    
    for name, symbol in tickers.items():
        try:
            # æŠ“å– Ticker
            ticker = yf.Ticker(symbol)
            # å–å¾—æ­·å²è³‡æ–™ (æ‹¿æœ€å¾Œå…©å¤©ä¾†è¨ˆç®—æ¼²è·Œ)
            hist = ticker.history(period="5d")
            
            if len(hist) >= 2:
                price = hist['Close'].iloc[-1]
                prev_close = hist['Close'].iloc[-2]
                change = price - prev_close
                percent = (change / prev_close) * 100
                
                # åˆ†é¡ï¼šæ˜¯ç”¨æ–¼ä¸Šæ–¹ Bar é‚„æ˜¯å³å´åˆ—è¡¨
                is_macro = name in ["ğŸ˜° ææ…ŒæŒ‡æ•¸ (VIX)", "ğŸ‡ºğŸ‡¸ 10å¹´ç¾å‚µ", "ğŸ’µ ç¾å…ƒæŒ‡æ•¸", "ğŸ›¢ï¸ åŸæ²¹ (WTI)"]
                
                data_list.append({
                    "name": name,
                    "price": float(f"{price:.2f}"),
                    "change": float(f"{change:.2f}"),
                    "percent": float(f"{percent:.2f}"),
                    "is_macro": is_macro # æ¨™è¨˜ä¸€ä¸‹ï¼Œæ–¹ä¾¿å‰ç«¯åˆ†é–‹é¡¯ç¤º
                })
                print(f"   âœ… {name}: {price:.2f}")
            else:
                print(f"   âš ï¸ {name} æ•¸æ“šä¸è¶³")
                
        except Exception as e:
            print(f"   âŒ {name} å¤±æ•—: {e}")
            
    return data_list

def get_ai_news():
    if not NEWS_API_KEY: return []
    final_news = []
    
    # ã€æ”¹å‹• 1ã€‘å®šç¾©ã€Œæ¬Šå¨åª’é«”ã€åå–® (Whitelist)
    # èˆ‡å…¶éæ¿¾åƒåœ¾ï¼Œä¸å¦‚ç›´æ¥æŒ‡å®šåªçœ‹å¤§ä½¬ã€‚é€™æ¨£æŠ“åˆ°çš„æ–°è 99% éƒ½æ˜¯é‡é»ã€‚
    # åŒ…å«ï¼šè·¯é€ã€CNBCã€å½­åšã€é›…è™è²¡ç¶“ã€è¯çˆ¾è¡—æ—¥å ±ã€TechCrunch (ç§‘æŠ€)ã€CoinDesk (å¹£åœˆ)
    trusted_domains = "reuters.com,cnbc.com,bloomberg.com,finance.yahoo.com,wsj.com,techcrunch.com,coindesk.com,decrypt.co"
    
    for category, query in CATEGORIES.items():
        print(f"ğŸ” è™•ç†æ–°è: {category} (ç¯©é¸æ¬Šå¨åª’é«”)...")
        
        # ã€æ”¹å‹• 2ã€‘API åƒæ•¸å¤§å‡ç´š
        # - domains={trusted_domains}: åªå¾ä¸Šé¢çš„æ¬Šå¨åª’é«”æŠ“
        # - sortBy=popularity: æ”¹æŠ“ã€Œç†±é–€åº¦ã€æœ€é«˜çš„æ–°èï¼Œç¢ºä¿æ˜¯å¸‚å ´ç„¦é»
        # - pageSize=10: æ“´å¤§æœå°‹ç¯„åœåˆ° 10 ç¯‡ (è®€å¤šå•²)
        url = f"https://newsapi.org/v2/everything?q={query}&language=en&domains={trusted_domains}&sortBy=popularity&pageSize=10&apiKey={NEWS_API_KEY}"
        
        try:
            response = requests.get(url).json()
            articles = response.get("articles", [])
            print(f"   -> å¾æ¬Šå¨åª’é«”æ‰¾åˆ° {len(articles)} ç¯‡ç†±é–€å ±å°")
        except: continue

        # ã€æ”¹å‹• 3ã€‘é›–ç„¶æŠ“äº† 10 ç¯‡ï¼Œä½†ç‚ºäº†ä¸çˆ† AI é¡åº¦ï¼Œæˆ‘å€‘åªåˆ†æã€Œå‰ 5 ç¯‡ã€
        # å› ç‚ºå·²ç¶“æŒ‰ç†±é–€åº¦æ’åºäº†ï¼Œå‰ 5 ç¯‡ä¸€å®šæ˜¯æœ€é‡è¦çš„
        for art in articles[:5]:
            prompt = f"""
            ä½ æ˜¯ä¸€ä½è¯çˆ¾è¡—åŸºé‡‘ç¶“ç†ã€‚è«‹é–±è®€ä»¥ä¸‹é‡è¦è²¡ç¶“æ–°èï¼š
            æ¨™é¡Œ: {art['title']}
            å…§å®¹: {art['description']}

            è«‹åš´æ ¼åˆ¤æ–·ï¼šé€™å‰‡æ–°èå°å¸‚å ´æœ‰å¤šé‡è¦ï¼Ÿ
            - å¦‚æœæ˜¯é‡å¤§æ”¿ç­–ã€è²¡å ±ã€ä½µè³¼æˆ–å´©ç›¤ï¼Œscore çµ¦ 8-10 åˆ†ã€‚
            - å¦‚æœåªæ˜¯æ™®é€šè§€é»æˆ–å°æ–°èï¼Œscore çµ¦ 1-4 åˆ†ã€‚

            è«‹å›å‚³å–®ä¸€ JSON ç‰©ä»¶ (ç¹é«”ä¸­æ–‡)ï¼š
            {{
                "title_zh": "ä¸­æ–‡æ¨™é¡Œ",
                "summary_zh": "50å­—å…§ä¸­æ–‡ç²¾è¯æ‘˜è¦",
                "impact": "åˆ©å¤š / åˆ©ç©º / ä¸­æ€§",
                "score": 8
            }}
            """
            
            try:
                ai_response = model.generate_content(prompt)
                analysis = json.loads(ai_response.text)
                
                if isinstance(analysis, list): analysis = analysis[0]
                
                # åªæœ‰åˆ†æ•¸å¤§æ–¼ 0 çš„æ‰åŠ å…¥ (éæ¿¾æ‰ AI èªç‚ºå®Œå…¨ä¸é‡è¦çš„)
                if analysis.get("score", 0) > 0:
                    final_news.append({
                        "category": category,
                        "title": analysis.get("title_zh", art['title']),
                        "link": art['url'],
                        "date": art['publishedAt'][:10],
                        "summary": analysis.get("summary_zh", "AI æœªèƒ½ç”Ÿæˆæ‘˜è¦"),
                        "impact": analysis.get("impact", "ä¸­æ€§"),
                        "score": analysis.get("score", 5)
                    })
                    print(f"   âœ… åˆ†ææˆåŠŸ (åˆ†): {analysis.get('title_zh')} (Score: {analysis.get('score')})")
                
                time.sleep(2) # ä¼‘æ¯ä¸€ä¸‹
                
            except Exception as e:
                print(f"   âš ï¸ åˆ†æå¤±æ•—: {e}")
                continue

    # æœ€å¾Œæ’åºï¼šåˆ†æ•¸é«˜çš„æ”¾æœ€å‰é¢
    return sorted(final_news, key=lambda x: x['score'], reverse=True)

# ================= 3. ä¸»ç¨‹å¼ =================
if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• No-Finnhub å…è²»ç‰ˆ (yfinance)...")
    
    # æŠ“å–æ‰€æœ‰æ•¸æ“š
    all_market_data = get_market_and_macro()
    
    # åˆ†æ‹†æ•¸æ“šçµ¦å‰ç«¯
    market_indices = [x for x in all_market_data if not x['is_macro']]
    macro_indicators = [x for x in all_market_data if x['is_macro']]
    
    final_output = {
        "update_time": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "market": market_indices, # ä¸Šæ–¹çš„æŒ‡æ•¸
        "news": get_ai_news(),    # ä¸­é–“çš„æ–°è
        "macro": macro_indicators # å³é‚Šçš„å®è§€æ•¸æ“š (å–ä»£æ—¥æ›†)
    }
    
    with open("daily_news.json", "w", encoding="utf-8") as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)
    print("ğŸ‰ å®Œæˆï¼")
