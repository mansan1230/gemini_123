import os
import requests
import json
import time
import yfinance as yf # å¼•å…¥ Yahoo Finance
import google.generativeai as genai
from datetime import datetime

# ================= 1. è¨­å®šå€ =================
NEWS_API_KEY = os.getenv("NEWS_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Debug
print(f"Checking Keys...")
print(f"- NEWS: {'âœ…' if NEWS_API_KEY else 'âŒ'}")
print(f"- GEMINI: {'âœ…' if GEMINI_API_KEY else 'âŒ'}")

# æ¨¡å‹è¨­å®š (Gemini 1.5 Flash)
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY.strip())
    model = genai.GenerativeModel(
        'gemini-2.0-flash',
        generation_config={"response_mime_type": "application/json"}
    )

# æ–°èé—œéµå­—
CATEGORIES = {
    "ğŸ”¥ å¸‚å ´é ­æ¢": "stock market OR federal reserve OR economy",
    "ğŸ¤– äººå·¥æ™ºæ…§": "Artificial Intelligence OR Nvidia OR OpenAI",
    "ğŸ’° åŠ å¯†è²¨å¹£": "Bitcoin OR Ethereum OR Crypto"
}

# ================= 2. æŠ“å–å‡½æ•¸ (yfinance ç‰ˆ) =================

def get_market_and_macro():
    """
    ä¸€æ¬¡éæŠ“å–ã€Œå¸‚å ´æŒ‡æ•¸ã€åŒã€Œå®è§€æŒ‡æ¨™ã€
    ä½¿ç”¨ yfinanceï¼Œå®Œå…¨å…è²»ï¼Œä¸ç”¨ Key
    """
    print("ğŸ“Š æ­£åœ¨é€é Yahoo Finance æŠ“å–æ•¸æ“š...")
    
    # å®šç¾©ä»£ç¢¼
    tickers = {
        # --- å¸‚å ´æŒ‡æ•¸ ---
        "ğŸ‡ºğŸ‡¸ S&P 500": "^GSPC",
        "ğŸ‡ºğŸ‡¸ Nasdaq": "^IXIC",
        "ğŸ‡­ğŸ‡° æ’ç”ŸæŒ‡æ•¸": "^HSI",
        "ğŸª™ Bitcoin": "BTC-USD",
        
        # --- å®è§€æŒ‡æ¨™ (å–ä»£æ—¥æ›†) ---
        "ğŸ˜° ææ…ŒæŒ‡æ•¸ (VIX)": "^VIX",
        "ğŸ‡ºğŸ‡¸ 10å¹´ç¾å‚µ": "^TNX",
        "ğŸ’µ ç¾å…ƒæŒ‡æ•¸": "DX-Y.NYB",
        "ğŸ›¢ï¸ åŸæ²¹ (WTI)": "CL=F"
    }
    
    data_list = []
    
    for name, symbol in tickers.items():
        try:
            # æŠ“å– Ticker
            ticker = yf.Ticker(symbol)
            # å–å¾—æ­·å²è³‡æ–™ (æ‹¿æœ€å¾Œå…©å¤©ä¾†è¨ˆç®—æ¼²è·Œ)
            hist = ticker.history(period="5d")
            
            if len(hist) >= 2:
                price = hist['Close'].iloc[-1]
                prev_close = hist['Close'].iloc[-2]
                change = price - prev_close
                percent = (change / prev_close) * 100
                
                # åˆ†é¡ï¼šæ˜¯ç”¨æ–¼ä¸Šæ–¹ Bar é‚„æ˜¯å³å´åˆ—è¡¨
                is_macro = name in ["ğŸ˜° ææ…ŒæŒ‡æ•¸ (VIX)", "ğŸ‡ºğŸ‡¸ 10å¹´ç¾å‚µ", "ğŸ’µ ç¾å…ƒæŒ‡æ•¸", "ğŸ›¢ï¸ åŸæ²¹ (WTI)"]
                
                data_list.append({
                    "name": name,
                    "price": float(f"{price:.2f}"),
                    "change": float(f"{change:.2f}"),
                    "percent": float(f"{percent:.2f}"),
                    "is_macro": is_macro # æ¨™è¨˜ä¸€ä¸‹ï¼Œæ–¹ä¾¿å‰ç«¯åˆ†é–‹é¡¯ç¤º
                })
                print(f"   âœ… {name}: {price:.2f}")
            else:
                print(f"   âš ï¸ {name} æ•¸æ“šä¸è¶³")
                
        except Exception as e:
            print(f"   âŒ {name} å¤±æ•—: {e}")
            
    return data_list

def get_ai_news():
    if not NEWS_API_KEY: return []
    final_news = []
    
    # æŒ‡å®šæ¬Šå¨åª’é«” (ç™½åå–®)
    trusted_domains = "reuters.com,cnbc.com,bloomberg.com,finance.yahoo.com,wsj.com,techcrunch.com,coindesk.com,decrypt.co"
    
    for category, query in CATEGORIES.items():
        print(f"ğŸ” è™•ç†æ–°è: {category}...")
        
        # æŠ“å– 15 ç¯‡ï¼Œè®“æˆ‘å€‘æœ‰æ›´å¤šé¸æ“‡ä¾†éæ¿¾
        url = f"https://newsapi.org/v2/everything?q={query}&language=en&domains={trusted_domains}&sortBy=popularity&pageSize=15&apiKey={NEWS_API_KEY}"
        
        try:
            response = requests.get(url).json()
            articles = response.get("articles", [])
        except: continue

        # ã€æ©Ÿåˆ¶ 1ã€‘åˆ†é¡å…§çš„ã€Œå·²æ”¶éŒ„ä¸»é¡Œã€æ¸…å–®
        # æ¯æ¬¡æ› Category å°±æ¸…ç©ºï¼Œä½†åŒä¸€å€‹ Category å…§æœƒç´¯ç©
        current_category_topics = [] 
        
        count = 0 # è©²åˆ†é¡ç›®å‰æ”¶éŒ„äº†å¹¾ç¯‡
        
        for art in articles:
            # å¦‚æœé€™åˆ†é¡å·²ç¶“æ”¶äº† 3 ç¯‡ï¼Œå°±å¤ äº†ï¼Œæ›ä¸‹ä¸€å€‹åˆ†é¡
            if count >= 3: 
                break

            # ã€æ©Ÿåˆ¶ 2ã€‘Python å±¤ç´šéæ¿¾ï¼šæ¨™é¡Œå®Œå…¨ä¸€æ¨£çš„ç›´æ¥è·³é
            if any(art['title'] == t for t in current_category_topics):
                continue

            # å°‡ã€Œç›®å‰å·²æœ‰çš„ä¸»é¡Œã€è®Šæˆå­—ä¸²ï¼Œå‚³çµ¦ AI åƒè€ƒ
            existing_topics_str = "ã€".join(current_category_topics) if current_category_topics else "ç„¡"

            prompt = f"""
            ä½ æ˜¯ä¸€ä½éå¸¸åš´æ ¼çš„è¯çˆ¾è¡—æ–°èç·¨è¼¯ã€‚
            
            ã€ä»»å‹™ç›®æ¨™ã€‘
            è«‹å¯©æ ¸é€™ç¯‡æ–°èï¼Œæ±ºå®šæ˜¯å¦æ”¶éŒ„ã€‚æˆ‘å€‘è¦çµ¦è®€è€…ã€Œå¤šæ¨£åŒ–ã€çš„è³‡è¨Šï¼Œä¸è¦é‡è¤‡çš„å…§å®¹ã€‚

            ã€ç•¶å‰æ–°èã€‘
            æ¨™é¡Œ: {art['title']}
            å…§å®¹: {art['description']}

            ã€æœ¬åˆ†é¡å·²æ”¶éŒ„çš„æ–°èä¸»é¡Œã€‘
            {existing_topics_str}

            ã€åˆ¤æ–·æ¨™æº–ã€‘
            1. é‡è¦æ€§ï¼šé€™æ˜¯å¦æ˜¯å¸‚å ´ç„¦é»ï¼Ÿ(æ˜¯->é«˜åˆ†)
            2. é‡è¤‡æ€§ï¼šé€™ç¯‡æ–°èçš„å…§å®¹æ˜¯å¦è·Ÿã€Œå·²æ”¶éŒ„çš„ä¸»é¡Œã€é«˜åº¦é‡è¤‡ï¼Ÿ
               - å¦‚æœé‡è¤‡ (ä¾‹å¦‚éƒ½è¬› Bitcoin ç ´ 10è¬)ï¼Œè«‹ç›´æ¥çµ¦ score: 0ï¼Œä¸è¦æ”¶éŒ„ã€‚
               - å¦‚æœæ˜¯æ–°è§’åº¦ (ä¾‹å¦‚ä¸€ç¯‡è¬›åƒ¹æ ¼ï¼Œé€™ç¯‡è¬›ç›£ç®¡)ï¼Œå¯ä»¥æ”¶éŒ„ã€‚

            è«‹å›å‚³å–®ä¸€ JSON ç‰©ä»¶ï¼š
            {{
                "title_zh": "ä¸­æ–‡æ¨™é¡Œ",
                "summary_zh": "50å­—å…§ä¸­æ–‡æ‘˜è¦",
                "impact": "åˆ©å¤š / åˆ©ç©º / ä¸­æ€§",
                "score": 0 (é‡è¤‡æˆ–ä¸é‡è¦) æˆ– 8-10 (é‡è¦ä¸”ç¨ç‰¹)
            }}
            """
            
            try:
                ai_response = model.generate_content(prompt)
                analysis = json.loads(ai_response.text)
                
                # è‡ªå‹•ä¿®æ­£åˆ—è¡¨æ ¼å¼
                if isinstance(analysis, list): analysis = analysis[0]
                
                # ã€æ©Ÿåˆ¶ 3ã€‘åªæ”¶éŒ„åˆ†æ•¸ > 0 çš„ (ä¸é‡è¤‡çš„)
                if analysis.get("score", 0) > 0:
                    final_news.append({
                        "category": category,
                        "title": analysis.get("title_zh", art['title']),
                        "link": art['url'],
                        "date": art['publishedAt'][:10],
                        "summary": analysis.get("summary_zh", "AI æœªèƒ½ç”Ÿæˆæ‘˜è¦"),
                        "impact": analysis.get("impact", "ä¸­æ€§"),
                        "score": analysis.get("score", 5)
                    })
                    
                    # æˆåŠŸæ”¶éŒ„å¾Œï¼ŒæŠŠé€™å€‹æ¨™é¡ŒåŠ å…¥ã€Œå·²æ”¶éŒ„æ¸…å–®ã€ï¼Œè®“ä¸‹ä¸€ç¯‡æ–°èé¿é–‹
                    # ç‚ºäº†ç¯€çœ Tokenï¼Œæˆ‘å€‘åªå­˜ä¸­æ–‡æ¨™é¡Œ
                    current_category_topics.append(analysis.get("title_zh"))
                    count += 1
                    
                    print(f"   âœ… æ”¶éŒ„: {analysis.get('title_zh')}")
                else:
                    print(f"   ğŸš« è·³é (é‡è¤‡æˆ–ä¸é‡è¦): {art['title'][:20]}...")
                
                time.sleep(2) 
                
            except Exception as e:
                print(f"   âš ï¸ AI éŒ¯èª¤: {e}")
                continue

    return sorted(final_news, key=lambda x: x['score'], reverse=True)

# ================= 3. ä¸»ç¨‹å¼ =================
if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• No-Finnhub å…è²»ç‰ˆ (yfinance)...")
    
    # æŠ“å–æ‰€æœ‰æ•¸æ“š
    all_market_data = get_market_and_macro()
    
    # åˆ†æ‹†æ•¸æ“šçµ¦å‰ç«¯
    market_indices = [x for x in all_market_data if not x['is_macro']]
    macro_indicators = [x for x in all_market_data if x['is_macro']]
    
    final_output = {
        "update_time": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "market": market_indices, # ä¸Šæ–¹çš„æŒ‡æ•¸
        "news": get_ai_news(),    # ä¸­é–“çš„æ–°è
        "macro": macro_indicators # å³é‚Šçš„å®è§€æ•¸æ“š (å–ä»£æ—¥æ›†)
    }
    
    with open("daily_news.json", "w", encoding="utf-8") as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)
    print("ğŸ‰ å®Œæˆï¼")
